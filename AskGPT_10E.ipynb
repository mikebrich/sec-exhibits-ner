{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkVlhQlZu4kL"
   },
   "source": [
    "## API key\n",
    "\n",
    "### Get one\n",
    "\n",
    "To run this code, you need an API key from Open AI. This involves giving them your credit card and setting up spending limits. \n",
    "\n",
    "### Using it\n",
    "\n",
    "I run this file locally via Jupyterlab, so it's in a folder with `gpt_api.txt` which contains my API key. \n",
    "\n",
    "To run this file in Google Colab, you _could_ directly type your API key into the notebook below, **but this is a bad idea.** \n",
    "\n",
    "Instead, one common way is to store the API key in a file on your Google Drive and then access it from the Colab notebook. Here's how you can do it:\n",
    "\n",
    "1.    Create a new text file on your Google Drive and store your API key in it. Name the file something like `gpt_api.txt`.\n",
    "1.    Mount your Google Drive to the Google Colab notebook by running the following code block.\n",
    "    ```python\n",
    "    import openai\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    with open('/content/drive/gpt_api.txt', 'r') as f:\n",
    "        openai.api_key = f.read().strip()\n",
    "    ```\n",
    "1.     This will prompt you to click on a link to authorize the connection. Follow the instructions, and copy the authorization code into the input box that appears in the Colab notebook. You can now continue on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E-YUQkM4lqZS"
   },
   "outputs": [],
   "source": [
    "# !pip install openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwGSI_l-lQI0",
    "outputId": "48bed0b3-2502-49c2-d1a1-76598c0d0a40"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# don't type the key in this file! open it from file that is in gitignore, github secrets, or in your google drive\n",
    "\n",
    "with open('gpt_api.txt', 'r') as f:\n",
    "    openai.api_key = f.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNnWIc3umGnF"
   },
   "source": [
    "## Define key functions to do the lift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read this\n",
    "\n",
    "https://platform.openai.com/docs/guides/chat/introduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm not sure which model the below is, but it's not the super cheap gpt-3.5-turbo\n",
    "\n",
    "# the cheaper option is something like this:\n",
    "openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "8seK4DtvuqrX"
   },
   "outputs": [],
   "source": [
    "# gpt 4.0 wrote this mostly\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import (  # used during dev - display(Markdown(markdown_table)) prints nice\n",
    "    Markdown,\n",
    "    display,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set Pandas display options to show full string\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "def ask_openai(question, data):\n",
    "    prompt = f\"{data}\\n---\\n{question}\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=70,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "def parse_file(filename):\n",
    "\n",
    "    # Define your question related to the loan application\n",
    "    question = \"Output a tab separated list containing two items: the name of the buyer, and the name of the seller.\"\n",
    "\n",
    "    # remove the html\n",
    "    with open(filename, \"r\") as fp:\n",
    "        raw = BeautifulSoup(fp.read(), 'html.parser').get_text()\n",
    "\n",
    "    return ask_openai(question, raw[:1850])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "8seK4DtvuqrX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "file_sentence_dict = {}\n",
    "files = glob.glob(\"inputs/*\") #get all the files in the inputs folder\n",
    "\n",
    "for file in tqdm(files,total=len(files)):\n",
    "    file_sentence_dict.update({file: parse_file(file)}) #update the dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs\\\\ex10-11.txt': 'Baxter Healthcare Corporation\\tCFC International, Inc.',\n",
       " 'inputs\\\\ex10.txt': 'Baxter Healthcare Corporation\\tCFC International'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_sentence_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>buyer</th>\n",
       "      <th>seller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inputs\\ex10-11.txt</td>\n",
       "      <td>Baxter Healthcare Corporation</td>\n",
       "      <td>CFC International, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inputs\\ex10.txt</td>\n",
       "      <td>Baxter Healthcare Corporation</td>\n",
       "      <td>CFC International</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             document                          buyer                   seller\n",
       "0  inputs\\ex10-11.txt  Baxter Healthcare Corporation  CFC International, Inc.\n",
       "1     inputs\\ex10.txt  Baxter Healthcare Corporation        CFC International"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(file_sentence_dict.items(), columns=['document', 'buyer_seller'])\n",
    "df[['buyer', 'seller']] = df['buyer_seller'].str.split('\\t', expand=True)\n",
    "df = df.drop('buyer_seller', axis=1)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fermi estimate  of the project cost\n",
    "\n",
    "Price: 0.002 per 1k tokens **in reply**\n",
    "\n",
    "So\n",
    "\n",
    "Cost = # docs * # tokens in reply per doc * 0.002/1000\n",
    "\n",
    "The reply above was 10 tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open AI's tokenizer\n",
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "sent = 'Baxter Healthcare Corporation\\tCFC International, Inc.'\n",
    "len(encoding.encode(sent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 0.25 million docs. \n",
    "\n",
    "## THE ESTIMATE, IN DOLLARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = 250000\n",
    "toks_per = 10\n",
    "cost_per_tok = 0.002/1000\n",
    "\n",
    "files*toks_per*cost_per_tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't eve believe that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed and rate limits\n",
    "\n",
    "I sent 1850 characters, which OpenAI says is 376 tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode('''<FILENAME>ex10.txt\n",
    "<DESCRIPTION>CFC INTERNATIONAL, INC.-BAXTER PURCHASE AGREEMENT\n",
    "<TEXT>\n",
    "Exhibit 10.9\n",
    "\n",
    "\n",
    "                               PURCHASE AGREEMENT\n",
    "\n",
    "         This Agreement, effective March 1, 2001 is between CFC International, a\n",
    "Delaware corporation, with offices at 500 State Street, Chicago Heights,\n",
    "Illinois 60411 (\"Seller\") and Baxter Healthcare Corporation, a Delaware\n",
    "corporation, with offices at One Baxter Parkway, Deerfield, Illinois 60015 on\n",
    "behalf or its self and its affiliates (entities controlling, controlled by, or\n",
    "under common control with Baxter)(\"Buyer\").\n",
    "\n",
    "                                 1.0 Background\n",
    "\n",
    "\n",
    "         1.1 Seller produces hot stamping foil which conforms and meets the\n",
    "Specification Requirements submitted, accepted and in Seller's possession for\n",
    "the Specification numbers listed attached in the Exhibit A., hereafter referred\n",
    "to as \"Products\". Product Specifications may be revised from time to time and\n",
    "new Specifications and numbers added by mutual agreement between parties. Buyer\n",
    "requires foil for use in printing flexible packaging.\n",
    "\n",
    "\n",
    "                                2.0 Distribution\n",
    "\n",
    "\n",
    "         2.1 Subject to the terms and conditions of this Agreement, Seller shall\n",
    "manufacture and sell Products to Buyer, and Buyer shall purchase Products for\n",
    "manufacture into goods for use or resale in any country in the world. Buyer\n",
    "agrees to purchase all their global foiling requirements from seller, or as\n",
    "stated in Section 13.2.\n",
    "\n",
    "\n",
    "                            3.0 Shipment of Products\n",
    "\n",
    "\n",
    "         3.1 Seller will ship Products, F.O.B. Seller's facility, freight\n",
    "collect, to locations specified by Buyer and via carriers specified by Buyer.\n",
    "\n",
    "         3.2 Seller agrees to maintain negotiated consignment inventory at\n",
    "Baxter's locations per specific plant consignment agreements.\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input token rate limit is 60000 per minute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can do this many contracts per minute \n",
    "(\n",
    "    60000 # tokens limit per nute\n",
    "    /\n",
    "    400   # conservative guess tokens per contract \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only allowed to do 60 requests a second. But a single request can \"batch\" multiple prompts. \n",
    "\n",
    "So, 50 times a minute, send 3 contracts. sleep(1.2) between calls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216000.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contracts per day\n",
    "(\n",
    "    # num contracts per minute\n",
    "    (\n",
    "        60000 # tokens per minute\n",
    "        /\n",
    "        400   # tokens per contract (if the lenght above is kept)\n",
    "    )\n",
    "    *\n",
    "    60*24 # minutes in a day\n",
    ") "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
